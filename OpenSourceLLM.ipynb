{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG pipeline using Open Source Large Languages\n",
        "\n",
        "Chat with Website using Zephyr 7B model"
      ],
      "metadata": {
        "id": "J177jX51J1Li"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "Syag3oIcKHM0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L18fYAOPJzZX"
      },
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import RAG components required to build pipeline"
      ],
      "metadata": {
        "id": "4FopYAa6Krjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain.vectorstores import FAISS, Chroma\n",
        "from langchain.chains import RetrievalQA, LLMChain"
      ],
      "metadata": {
        "id": "kGXeRCdILsha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "HF_TOKEN = getpass(\"HF Token:\")\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEfA-vDcKrI5",
        "outputId": "fef54745-936d-4b05-bd20-9bde05ab5a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HF Token:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## External data/document - ETL"
      ],
      "metadata": {
        "id": "KFyNhHmsMYBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "ziRBTGT3NF7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEBSITE_URL = \"https://python.langchain.com/docs/get_started/introduction\""
      ],
      "metadata": {
        "id": "h7QVgNPmLkKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(WEBSITE_URL)\n",
        "loader.requests_per_second = 1\n",
        "docs = loader.aload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOrnY8dgMdxt",
        "outputId": "625250fe-0062-45e3-b3b4-5dd28fe6b57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  7.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "K1TTrH5QNQxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112ffeb6-b594-4df3-c062-8b95a2df84cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"\\n\\n\\n\\n\\nIntroduction | ü¶úÔ∏èüîó Langchain\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentDocsUse casesIntegrationsGuidesAPIMorePeopleVersioningChangelogContributingTemplatesCookbooksTutorialsYouTubeü¶úÔ∏èüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS Docsüí¨SearchGet startedIntroductionInstallationQuickstartSecurityLangChain Expression LanguageGet startedWhy use LCELInterfaceStreamingHow toCookbookLangChain Expression Language (LCEL)ModulesModel I/ORetrievalAgentsChainsMoreLangServeLangSmithLangGraphGet startedIntroductionOn this pageIntroductionLangChain is a framework for developing applications powered by language models. It enables applications that:Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)This framework consists of several parts.LangChain Libraries: The Python and JavaScript libraries. Contains interfaces and integrations for a myriad of components, a basic run time for combining these components into chains and agents, and off-the-shelf implementations of chains and agents.LangChain Templates: A collection of easily deployable reference architectures for a wide variety of tasks.LangServe: A library for deploying LangChain chains as a REST API.LangSmith: A developer platform that lets you debug, test, evaluate, and monitor chains built on any LLM framework and seamlessly integrates with LangChain.Together, these products simplify the entire application lifecycle:Develop: Write your applications in LangChain/LangChain.js. Hit the ground running using Templates for reference.Productionize: Use LangSmith to inspect, test and monitor your chains, so that you can constantly improve and deploy with confidence.Deploy: Turn any chain into an API with LangServe.LangChain Libraries\\u200bThe main value props of the LangChain packages are:Components: composable tools and integrations for working with language models. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or notOff-the-shelf chains: built-in assemblages of components for accomplishing higher-level tasksOff-the-shelf chains make it easy to get started. Components make it easy to customize existing chains and build new ones.The LangChain libraries themselves are made up of several different packages.langchain-core: Base abstractions and LangChain Expression Language.langchain-community: Third party integrations.langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.Get started\\u200bHere‚Äôs how to install LangChain, set up your environment, and start building.We recommend following our Quickstart guide to familiarize yourself with the framework by building your first LangChain application.Read up on our Security best practices to make sure you're developing safely with LangChain.noteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.LangChain Expression Language (LCEL)\\u200bLCEL is a declarative way to compose chains. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest ‚Äúprompt + LLM‚Äù chain to the most complex chains.Overview: LCEL and its benefitsInterface: The standard interface for LCEL objectsHow-to: Key features of LCELCookbook: Example code for accomplishing common tasksModules\\u200bLangChain provides standard, extendable interfaces and integrations for the following modules:Model I/O\\u200bInterface with language modelsRetrieval\\u200bInterface with application-specific dataAgents\\u200bLet models choose which tools to use given high-level directivesExamples, ecosystem, and resources\\u200bUse cases\\u200bWalkthroughs and techniques for common end-to-end use cases, like:Document question answeringChatbotsAnalyzing structured dataand much more...Integrations\\u200bLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of integrations.Guides\\u200bBest practices for developing with LangChain.API reference\\u200bHead to the reference section for full documentation of all classes and methods in the LangChain and LangChain Experimental Python packages.Developer's guide\\u200bCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.Help us out by providing feedback on this documentation page:PreviousGet startedNextInstallationLangChain LibrariesGet startedLangChain Expression Language (LCEL)ModulesExamples, ecosystem, and resourcesUse casesIntegrationsGuidesAPI referenceDeveloper's guideCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2024 LangChain, Inc.\\n\\n\\n\\n\", metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'})]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Splitting - Chunking"
      ],
      "metadata": {
        "id": "Z_A2nX3-Ptgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=20)\n",
        "chunks = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "Bouw0M5ANVqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsc6K_Z3NnhT",
        "outputId": "eae58f49-4858-44a0-f116-edbb0f99ada2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Introduction | ü¶úÔ∏èüîó Langchain', metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jenEDd6hN7Cn",
        "outputId": "404df8f4-eaec-4260-d12c-4b6252f341f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Skip to main contentDocsUse casesIntegrationsGuidesAPIMorePeopleVersioningChangelogContributingTemplatesCookbooksTutorialsYouTubeü¶úÔ∏èüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS Docsüí¨SearchGet', metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLh3j6guOTLY",
        "outputId": "5458578a-1461-4bc9-d253-68fee0dbec8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Docsüí¨SearchGet startedIntroductionInstallationQuickstartSecurityLangChain Expression LanguageGet startedWhy use LCELInterfaceStreamingHow toCookbookLangChain Expression Language (LCEL)ModulesModel I/ORetrievalAgentsChainsMoreLangServeLangSmithLangGraphGet', metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-lh4cUSO5EH",
        "outputId": "3a33f321-c893-44b3-f802-23fe09df18c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='startedIntroductionOn this pageIntroductionLangChain is a framework for developing applications powered by language models. It enables applications that:Are context-aware: connect a language model to sources of context (prompt instructions, few shot', metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eZw3iXPPlGs",
        "outputId": "2603da7c-b099-4ab3-e041-de4a9020ea77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='few shot examples, content to ground its response in, etc.)Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)This framework consists of several parts.LangChain Libraries: The Python and', metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "wxL78Mn0P3N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
        "    api_key=HF_TOKEN, model_name=\"BAAI/bge-base-en-v1.5\"\n",
        ")"
      ],
      "metadata": {
        "id": "QcUdFP8cPz1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Store - FAISS or ChromaDB"
      ],
      "metadata": {
        "id": "cJMgeAOrQfuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "_rMc5YphQiFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmJth21AQx8V",
        "outputId": "3b4d5720-1f6f-4ae1-c449-d588c065999a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x7f3b218dd8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Langachain?\"\n",
        "search = vectorstore.similarity_search(query)"
      ],
      "metadata": {
        "id": "MxUNoeFeR7-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "45HgM9wsSCKH",
        "outputId": "39b132a8-ae11-4210-9aab-e686c338f301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Introduction | ü¶úÔ∏èüîó Langchain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retriever"
      ],
      "metadata": {
        "id": "4mVaIlkZRiXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"mmr\", #similarity\n",
        "    search_kwargs={'k': 4}\n",
        ")"
      ],
      "metadata": {
        "id": "rK67OkSQRbnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC4Xly8XSf26",
        "outputId": "380699b0-33a6-4e62-9792-b0f9e64132cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Introduction | ü¶úÔ∏èüîó Langchain', metadata={'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en', 'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain'}),\n",
              " Document(page_content='Templates: A collection of easily deployable reference architectures for a wide variety of tasks.LangServe: A library for deploying LangChain chains as a REST API.LangSmith: A developer platform that lets you debug, test, evaluate, and monitor chains', metadata={'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en', 'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain'}),\n",
              " Document(page_content=\"up on our Security best practices to make sure you're developing safely with LangChain.noteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.LangChain Expression Language (LCEL)\\u200bLCEL is a declarative\", metadata={'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en', 'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain'}),\n",
              " Document(page_content='few shot examples, content to ground its response in, etc.)Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)This framework consists of several parts.LangChain Libraries: The Python and', metadata={'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en', 'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain'})]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Large Language Model - Open Source"
      ],
      "metadata": {
        "id": "al9E1TqMS7Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"huggingfaceh4/zephyr-7b-alpha\",\n",
        "    model_kwargs={\"temperature\": 0.5, \"max_length\": 64,\"max_new_tokens\":512}\n",
        ")"
      ],
      "metadata": {
        "id": "MKDFEMDSS9ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template and User Input (Augment - Step 2)"
      ],
      "metadata": {
        "id": "_dy-nCxqTQTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Langchain?\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        " <|system|>\n",
        "You are an AI assistant that follows instruction extremely well.\n",
        "Please be truthful and give direct answers\n",
        "</s>\n",
        " <|user|>\n",
        " {query}\n",
        " </s>\n",
        " <|assistant|>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "C_pCkm2jTHtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG RetrievalQA chain"
      ],
      "metadata": {
        "id": "5Y2ukOe5TS6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=retriever)"
      ],
      "metadata": {
        "id": "aUEmwLYvTWG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = qa.run(prompt)"
      ],
      "metadata": {
        "id": "sVN8b7LIUMHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "6rQCeRzTUnQ2",
        "outputId": "93ea44d7-37c0-44b2-955d-441ec81e662c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The original question is as follows: \\n <|system|>\\nYou are an AI assistant that follows instruction extremely well.\\nPlease be truthful and give direct answers\\n</s>\\n <|user|>\\n What is Langchain?\\n </s>\\n <|assistant|>\\n\\nWe have provided an existing answer: The original question is as follows: \\n <|system|>\\nYou are an AI assistant that follows instruction extremely well.\\nPlease be truthful and give direct answers\\n</s>\\n <|user|>\\n What is Langchain?\\n </s>\\n <|assistant|>\\n\\nWe have provided an existing answer: The original question is as follows: \\n <|system|>\\nYou are an AI assistant that follows instruction extremely well.\\nPlease be truthful and give direct answers\\n</s>\\n <|user|>\\n What is Langchain?\\n </s>\\n <|assistant|>\\n\\nWe have provided an existing answer: Context information is below. \\n------------\\nIntroduction | ü¶úÔ∏èüîó Langchain\\n------------\\nGiven the context information and not prior knowledge, answer the question: \\n <|system|>\\nYou are an AI assistant that follows instruction extremely well.\\nPlease be truthful and give direct answers\\n</s>\\n <|user|>\\n What is Langchain?\\n </s>\\n <|assistant|>\\n\\nLangchain is an open-source Python library for building and deploying chatbots, knowledge assistants, and other conversational AI applications. It provides a set of tools and building blocks for working with text data, including natural language processing, text summarization, and question answering. Langchain is designed to be flexible and customizable, allowing developers to easily plug in their own data sources and customize the behavior of their chatbots.\\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\nare made up of several different packages.langchain-core: Base abstractions and LangChain Expression Language.langchain-community: Third party integrations.langchain: Chains, agents, and retrieval strategies that make up an application's cognitive\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\\n<|>\\nLangchain is an open-source Python library for building and deploying chatbots, knowledge assistants, and other conversational AI applications. It provides a set of tools and building blocks for working with text data, including natural language processing, text summarization, and question answering. Langchain is designed to be flexible and customizable, allowing developers to easily plug in their own data sources and customize the behavior of their chatbots. Langchain consists of several different packages: langchain-core, langchain-community, and langchain. Langchain-core provides base abstractions and LangChain Expression Language, langchain-community offers third-party integrations, and langchain is a combination of chains, agents, and retrieval strategies that make up an application's cognitive abilities.\\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\nuse cases, like:Document question answeringChatbotsAnalyzing structured dataand much more...Integrations\\u200bLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\\n<|>\\nLangchain is an open-source Python library for building and deploying chatbots, knowledge assistants, and other conversational AI applications. It provides a set of tools and building blocks for working with text data, including natural language processing, text summarization, and question answering. Langchain is designed to be flexible and customizable, allowing developers to easily plug in their own data sources and customize the behavior of their chatbots. Langchain consists of several different packages: langchain-core, langchain-community, and langchain. Langchain-core provides base abstractions and LangChain Expression Language, langchain-community offers third-party integrations, and langchain is a combination of chains, agents, and retrieval strategies that make up an application's cognitive abilities. Langchain's use cases include document question answering, chatbots, analyzing structured data, and more. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of integrations.\\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\nWe're a team of open-source contributors building LangChain for developers to build intelligent, conversational applications.\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\\n<|>\\nLangchain is an open-source Python library for building and deploying chatbots, knowledge assistants, and other conversational AI applications. It provides a set of tools and building blocks for working with text data, including natural language processing, text summarization, and question answering. Langchain is designed to be flexible and customizable, allowing developers to easily plug in their own data sources and customize the behavior of their chatbots. Langchain consists of several different packages: langchain-core, langchain-community, and langchain. Langchain-core provides base abstractions and LangChain Expression Language, langchain-community offers third-party integrations, and langchain is a combination of chains, agents, and retrieval strategies that make up an application's cognitive abilities. Langchain's use cases include document question answering, chatbots, analyzing structured data, and more. LangChain is part of a rich ecosystem of tools that integrate with our framework and\\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\nis a declarative way to compose chains. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest ‚Äúprompt + LLM‚Äù chain to the most complex chains.Overview: LCEL and its benefitsInterface: The\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\\n<|>\\nLangchain is an open-source Python library for building and deploying chatbots, knowledge assistants, and other conversational AI applications. It provides a set of tools and building blocks for working with text data, including natural language processing, text summarization, and question answering. Langchain is designed to be flexible and customizable, allowing developers to easily plug in their own data sources and customize the behavior of their chatbots. Langchain consists of several different packages: langchain-core, langchain-community, and langchain. Langchain-core provides base abstractions and LangChain Expression Language, langchain-community offers third-party integrations, and langchain is a combination of chains, agents, and retrieval strategies that make up an application's cognitive abilities. Langchain's use cases include document question answering, chatbots, analyzing structured data, and more. LangChain is part of a rich ecosystem of tools that integrate with our framework and\\n\\nLangChain Expression Language (LCEL) is a declarative way to compose chains. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest ‚Äúprompt + LLM‚Äù chain to the most complex chains. Overview: LCEL and its benefits. Interface: The LCEL interface allows for chaining of multiple steps together, with each step being represented by a function or method. This allows for the creation of complex pipelines and workflows, without the need for complex programming or scripting. The benefits of using LCEL include:\\n\\n1. Declarative: LCEL is a declarative language, which means that it is used to describe the desired output, rather than the steps needed to achieve it. This makes it easier to understand and maintain, as the logic is written in a more natural and intuitive way.\\n\\n2. No code changes: LCEL allows for the creation of complex pipelines and workflows, without the need for complex programming or scripting. This means that changes to the pipeline can be made without the need for recompilation or re-deployment, which can save time and resources.\\n\\n3. Reusability: LCEL allows for the creation of reusable components, which can be used across multiple pipelines and workflows. This can save time and resources, as well as improve consistency\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain"
      ],
      "metadata": {
        "id": "eOm3anhXTwg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "M4dKOO7QUTa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        " <|system|>\n",
        "You are an AI assistant that follows instruction extremely well.\n",
        "Please be truthful and give direct answers\n",
        "</s>\n",
        " <|user|>\n",
        " {query}\n",
        " </s>\n",
        " <|assistant|>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aBDfjug4U61T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "oGSLkCc7U8YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\": retriever,  \"query\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "hLfDSrrzU1kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"What is Langchain?\")"
      ],
      "metadata": {
        "id": "35B_JEcKVERB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyor1d0xVHnW",
        "outputId": "4d4254a5-a0f9-46ff-ee08-7aeb87c6dd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: \n",
            " <|system|>\n",
            "You are an AI assistant that follows instruction extremely well.\n",
            "Please be truthful and give direct answers\n",
            "</s>\n",
            " <|user|>\n",
            " What is Langchain?\n",
            " </s>\n",
            " <|assistant|>\n",
            "Langchain is a Python library for building chatbots, assistants, and other natural language processing applications. It offers a simple and consistent API for working with various text sources and output formats, making it easy to build complex NLP pipelines. Langchain supports a variety of text sources, including web pages, PDFs, and local text files, and output formats, including text, JSON, and CSV. It also offers support for popular NLP frameworks like SpaCy and NLTK, making it a popular choice for building NLP applications in Python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EIEoMsgcjJU9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}